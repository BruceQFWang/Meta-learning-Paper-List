# Meta learning/Learning to learn/AutoML

### Top
Suggested books by Mike Jordan at Berkeley:[link](https://news.ycombinator.com/item?id=1055389)

## Papers

### 2022
- <a name="todo"></a> On the Importance of Firth Bias Reduction in Few-Shot Classification (**ICLR2022**) [[paper](https://openreview.net/pdf?id=DNRADop4ksB)]
- <a name="todo"></a> Continuous-Time Meta-Learning with Forward Mode Differentiation (**ICLR2022**) [[paper](https://openreview.net/pdf?id=57PipS27Km)]
- <a name="todo"></a> Finetuned Language Models are Zero-Shot Learners (**ICLR2022**) [[paper](https://openreview.net/pdf?id=gEZrGCozdqR)]
- <a name="todo"></a> How to Train Your MAML to Excel in Few-Shot Classification (**ICLR2022**) [[paper](https://openreview.net/pdf?id=49h_IkpJtaE)]
- <a name="todo"></a> Task Affinity with Maximum Bipartite Matching in Few-Shot Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=u2GZOiUTbt)]
- <a name="todo"></a> Bootstrapped Meta-Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=b-ny3x071E5)]
- <a name="todo"></a> Meta-Learning with Fewer Tasks through Task Interpolation (**ICLR2022**) [[paper](https://openreview.net/pdf?id=ajXWF7bVR8d)]
- <a name="todo"></a> Vision-Based Manipulators Need to Also See from Their Hands (**ICLR2022**) [[paper](https://openreview.net/pdf?id=RJkAHKp7kNZ)]
- <a name="todo"></a> Differentiable Prompt Makes Pre-trained Language Models Better Few-shot Learners (**ICLR2022**) [[paper](https://openreview.net/pdf?id=u2GZOiUTbt)]
- <a name="todo"></a> Subspace Regularizers for Few-Shot Class Incremental Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=boJy41J-tnQ)]
- <a name="todo"></a> ConFeSS: A Framework for Single Source Cross-Domain Few-Shot Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=zRJu6mU2BaE)]
- <a name="todo"></a> Temporal Alignment Prediction for Supervised Representation Learning and Few-Shot Sequence Classification (**ICLR2022**) [[paper](https://openreview.net/pdf?id=p3DKPQ7uaAi)]
- <a name="todo"></a>  LFPT5: A Unified Framework for Lifelong Few-shot Language Learning Based on Prompt Tuning of T5 (**ICLR2022**) [[paper](https://openreview.net/pdf?id=HCRVf71PMF)]
- <a name="todo"></a>  Few-shot Learning via Dirichlet Tessellation Ensemble (**ICLR2022**) [[paper](https://openreview.net/pdf?id=6kCiVaoQdx9)]
- <a name="todo"></a>  Training Data Generating Networks: Shape Reconstruction via Bi-level Optimization (**ICLR2022**) [[paper](https://openreview.net/pdf?id=dDo8druYppX)]
- <a name="todo"></a>  Switch to Generalize: Domain-Switch Learning for Cross-Domain Few-Shot Classification (**ICLR2022**) [[paper](https://openreview.net/pdf?id=H-iABMvzIc)]
- <a name="todo"></a>  On the Role of Neural Collapse in Transfer Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=SwIp410B6aQ)]
- <a name="todo"></a>  Generalizing Few-Shot NAS with Gradient Matching (**ICLR2022**) [[paper](https://openreview.net/pdf?id=_jMtny3sMKU)]
- <a name="todo"></a>  Neural Variational Dropout Processes (**ICLR2022**) [[paper](https://openreview.net/pdf?id=lyLVzukXi08)]
- <a name="todo"></a>  Hierarchical Few-Shot Imitation with Skill Transition Models (**ICLR2022**) [[paper](https://openreview.net/pdf?id=xKZ4K0lTj_)]
- <a name="todo"></a>  Learning Prototype-oriented Set Representations for Meta-Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=WH6u2SvlLp4)]
- <a name="todo"></a>  Few-Shot Backdoor Attacks on Visual Object Tracking (**ICLR2022**) [[paper](https://openreview.net/pdf?id=qSV5CuSaK_a)]
- <a name="todo"></a>  Hierarchical Variational Memory for Few-shot Learning Across Domains (**ICLR2022**) [[paper](https://openreview.net/pdf?id=i3RI65sR7N)]
- <a name="todo"></a>  Prototype memory and attention mechanisms for few shot image generation (**ICLR2022**) [[paper](https://openreview.net/pdf?id=lY0-7bj0Vfz)]
- <a name="todo"></a>  Language-driven Semantic Segmentation (**ICLR2022**) [[paper](https://openreview.net/pdf?id=RriDjddCLN)]
- <a name="todo"></a>  Evolutionary Diversity Optimization with Clustering-based Selection for Reinforcement Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=74x5BXs4bWD)]
- <a name="todo"></a>  Vector-quantized Image Modeling with Improved VQGAN (**ICLR2022**) [[paper](https://openreview.net/pdf?id=pfNyExj7z2)]
- <a name="todo"></a>  Efficient Token Mixing for Transformers via Adaptive Fourier Neural Operators (**ICLR2022**) [[paper](https://openreview.net/pdf?id=EXHG-A3jlM)]
- <a name="todo"></a>  Synchromesh: Reliable Code Generation from Pre-trained Language Models (**ICLR2022**) [[paper](https://openreview.net/pdf?id=KmtVD97J43e)]
- <a name="todo"></a>  Knowledge Infused Decoding (**ICLR2022**) [[paper](https://openreview.net/pdf?id=upnDJ7itech)]
- <a name="todo"></a>  Transformers Can Do Bayesian Inference (**ICLR2022**) [[paper](https://openreview.net/pdf?id=KSugKcbNf9)]
- <a name="todo"></a>  Towards Better Understanding and Better Generalization of Low-shot Classification in Histology Images with Contrastive Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=kQ2SOflIOVC)]
- <a name="todo"></a>  Skill-based Meta-Reinforcement Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=jeLW-Fh9bV)]
- <a name="todo"></a>  Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty (**ICLR2022**) [[paper](https://openreview.net/pdf?id=GQd7mXSPua)]
- <a name="todo"></a>  Meta-Imitation Learning by Watching Video Demonstrations (**ICLR2022**) [[paper](https://openreview.net/pdf?id=KTPuIsx4pmo)]
- <a name="todo"></a>  Learning Prototype-oriented Set Representations for Meta-Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=WH6u2SvlLp4)]
- <a name="todo"></a>  Model-Based Offline Meta-Reinforcement Learning with Regularization (**ICLR2022**) [[paper](https://openreview.net/pdf?id=EBn0uInJZWh)]
- <a name="todo"></a>  Hindsight Foresight Relabeling for Meta-Reinforcement Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=P7OVkHEoHOZ)]
- <a name="todo"></a>  Contrastive Learning is Just Meta-Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=gICys3ITSmj)]
- <a name="todo"></a>  Meta Learning Low Rank Covariance Factors for Energy Based Deterministic Uncertainty (**ICLR2022**) [[paper](https://openreview.net/pdf?id=GQd7mXSPua)]
- <a name="todo"></a>  Unraveling Model-Agnostic Meta-Learning via The Adaptation Learning Rate (**ICLR2022**) [[paper](https://openreview.net/pdf?id=3rULBvOJ8D2)]
- <a name="todo"></a>  CoMPS: Continual Meta Policy Search (**ICLR2022**) [[paper](https://openreview.net/pdf?id=PVJ6j87gOHz)]
- <a name="todo"></a>  Meta-Imitation Learning by Watching Video Demonstrations (**ICLR2022**) [[paper](https://openreview.net/pdf?id=KTPuIsx4pmo)]
- <a name="todo"></a>  SUMNAS: Supernet with Unbiased Meta-Features for Neural Architecture Search (**ICLR2022**) [[paper](https://openreview.net/pdf?id=Z8FzvVU6_Kj)]
- <a name="todo"></a>  Learning Generalizable Representations for Reinforcement Learning via Adaptive Meta-learner of Behavioral Similarities (**ICLR2022**) [[paper](https://openreview.net/pdf?id=zBOI9LFpESK)]
- <a name="todo"></a>  Prospect Pruning: Finding Trainable Weights at Initialization using Meta-Gradients (**ICLR2022**) [[paper](https://openreview.net/pdf?id=AIgn9uwfcD1)]
- <a name="todo"></a>  Online Hyperparameter Meta-Learning with Hypergradient Distillation (**ICLR2022**) [[paper](https://openreview.net/pdf?id=01AMRlen9wJ)]
- <a name="todo"></a>  Task Relatedness-Based Generalization Bounds for Meta Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=A3HHaEdqAJL)]
- <a name="todo"></a>  Bootstrapped Meta-Learning (**ICLR2022**) [[paper](https://openreview.net/pdf?id=b-ny3x071E5)]
- <a name="todo"></a>  Fast Training of Neural Lumigraph Representations using Meta Learning (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/01931a6925d3de09e5f87419d9d55055-Abstract.html)]
- <a name="todo"></a>  Generalization Bounds for Meta-Learning via PAC-Bayes and Uniform Stability (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/1102a326d5f7c9e04fc3c89d0ede88c9-Abstract.html)]
- <a name="todo"></a>  MetaAvatar: Learning Animatable Clothed Human Models from Few Depth Images  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/1680829293f2a8541efa2647a0290f88-Abstract.html)]
- <a name="todo"></a>  Two Sides of Meta-Learning Evaluation: In vs. Out of Distribution   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/1e932f24dc0aa4e7a6ac2beec387416d-Abstract.html)]
- <a name="todo"></a>  Learning where to learn: Gradient sparsity in meta and continual learning  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/2a10665525774fa2501c2c8c4985ce61-Abstract.html)]
- <a name="todo"></a>  Generalization of Model-Agnostic Meta-Learning Algorithms: Recurring and Unseen Tasks   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/2b763288faedb7707c0748abe015ab6c-Abstract.html)]
- <a name="todo"></a>  Meta Two-Sample Testing: Learning Kernels for Testing with Limited Data  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/2e6d9c6052e99fcdfa61d9b9da273ca2-Abstract.html)]
- <a name="todo"></a>  Meta-learning with an Adaptive Task Scheduler  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/3dc4876f3f08201c7c76cb71fa1da439-Abstract.html)]
- <a name="todo"></a>  Towards Enabling Meta-Learning from Target Models  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/43baa6762fa81bb43b39c62553b2970d-Abstract.html)]
- <a name="todo"></a>  How Fine-Tuning Allows for Effective Meta-Learning   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/4a533591763dfa743a13affab1a85793-Abstract.html)]
- <a name="todo"></a>  Meta-Adaptive Nonlinear Control: Theory and Algorithms  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/52fc2aee802efbad698503d28ebd3a1f-Abstract.html)]
- <a name="todo"></a>  Meta-Learning Sparse Implicit Neural Representations    (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/61b1fb3f59e28c67f3925f3c79be81a1-Abstract.html)]

- <a name="todo"></a>  Meta Learning Backpropagation And Improving It   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/7608de7a475c0c878f60960d72a92654-Abstract.html)]
- <a name="todo"></a>  Revisit Multimodal Meta-Learning through the Lens of Multi-Task Learning(**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/7b3403f79b478699224bb449509694cf-Abstract.html)]
- <a name="todo"></a>  Noether Networks: meta-learning useful conserved quantities  (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/886ad506e0c115cf590d18ebb6c26561-Abstract.html)]
- <a name="todo"></a>  Statistically and Computationally Efficient Linear Meta-representation Learning   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/99e7e6ce097324aceb45f98299ceb621-Abstract.html)]
- <a name="todo"></a>  On sensitivity of meta-learning to support data   (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/ab73f542b6d60c4de151800b8abc0a6c-Abstract.html)]
- <a name="todo"></a>  Meta Internal Learning    (**NeurIPS2022**) [[paper](https://papers.nips.cc/paper/2021/hash/ac796a52db3f16bbdb6557d3d89d1c5a-Abstract.html)]



### 2019.3.19
**[1]** Andrychowicz, Marcin, et al. **Learning to learn by gradient descent by gradient descent.** Advances in Neural Information Processing Systems. 2016. [link](https://arxiv.org/pdf/1606.04474.pdf)   (使用LSTM学习梯度)


**[2]** Finn, Chelsea, Pieter Abbeel, and Sergey Levine.**Model-agnostic meta-learning for fast adaptation of deep networks.** Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.[link](https://arxiv.org/pdf/1703.03400.pdf) (二次梯度)

**[3]** Snell, Jake, Kevin Swersky, and Richard Zemel. **Prototypical networks for few-shot learning.** Advances in Neural Information Processing Systems. 2017.[link](http://papers.nips.cc/paper/6996-prototypical-networks-for-few-shot-learning.pdf) (四种度量网络的一个)

**[4]** Lake, Brenden M., Ruslan Salakhutdinov, and Joshua B. Tenenbaum. **Human-level concept learning through probabilistic program induction.** Science 350.6266 (2015): 1332-1338.[link](https://www.sas.upenn.edu/~astocker/lab/teaching-files/PSYC739-2016/Lake_etal2015.pdf)  (偏向于特征工程学习先验)

### 2019.3.25
**[5]** Sung, Flood, et al. **Learning to compare: Relation network for few-shot learning.** Proceedings of the IEEE Conference on Computer Vision and Pattern Recognition. 2018.[link](http://openaccess.thecvf.com/content_cvpr_2018/papers/Sung_Learning_to_Compare_CVPR_2018_paper.pdf) (四种度量网络的一个)

**[6]** Vinyals, Oriol, et al. **Matching networks for one shot learning.** Advances in neural information processing systems. 2016.[link](http://papers.nips.cc/paper/6385-matching-networks-for-one-shot-learning.pdf)  (四种度量网络的一个)

**[7]** Koch, Gregory, Richard Zemel, and Ruslan Salakhutdinov. **Siamese neural networks for one-shot image recognition.** ICML Deep Learning Workshop. Vol. 2. 2015.[link](http://www.cs.toronto.edu/~gkoch/files/msc-thesis.pdf) (孪生网络)

### 2019.3.27
**[8]** Ravi, Sachin, and Hugo Larochelle. **Optimization as a model for few-shot learning.** (2016).[link](https://openreview.net/pdf?id=rJY0-Kcll) 

### 2019.3.28
**[9]** Chen, Yutian, et al. **Learning to learn without gradient descent by gradient descent.** Proceedings of the 34th International Conference on Machine Learning-Volume 70. JMLR. org, 2017.[link](https://arxiv.org/pdf/1611.03824.pdf)  (梯度优化黑盒函数)

### 2019.3.31
**[10]** Xu, Ju, and Zhanxing Zhu. **Reinforced continual learning.** Advances in Neural Information Processing Systems. 2018.[link](https://papers.nips.cc/paper/7369-reinforced-continual-learning.pdf) 

### 2019.4.1
**[11]** Pham, Hieu, et al. **Efficient neural architecture search via parameter sharing.** arXiv preprint arXiv:1802.03268 (2018).[link](https://arxiv.org/pdf/1802.03268.pdf?fbclid=IwAR1RHoGyzFPepWpSyNA1TcySIjEto2scD7Fg3Pk6KOUygRNKXiA_r68MIkI)  

### 2019.4.2
**[12]** Elsken, Thomas, Jan Hendrik Metzen, and Frank Hutter. **Neural architecture search: A survey.** arXiv preprint arXiv:1808.05377 (2018).[link](https://arxiv.org/pdf/1808.05377.pdf) (很好的一篇NAS的综述)

### 2019.4.3
**[13]** Quanming, Yao, et al. **Taking human out of learning applications: A survey on automated machine learning.** arXiv preprint arXiv:1810.13306 (2018).[link](https://arxiv.org/pdf/1810.13306.pdf  (一篇不错的AutoML的综述)

### 2019.4.9
**[14]** Nichol, Alex, Joshua Achiam, and John Schulman. **On first-order meta-learning algorithms.** arXiv preprint arXiv:1803.02999 (2018).[link](https://arxiv.org/pdf/1803.02999.pdf)  (两篇分析并拓展MAML算法的文章，reptile版本)

**[15]** Antoniou, Antreas, Harrison Edwards, and Amos Storkey. **How to train your MAML.** arXiv preprint arXiv:1810.09502 (2018).[link](https://arxiv.org/pdf/1810.09502.pdf)  (两篇分析并拓展MAML算法的文章)

### 2019.4.17
**[16]** Frank Hutter, Lars Kotthoff, Joaquin Vanschoren**Automatic Machine Learning:Methods, Systems, Challenges** .[link](https://www.automl.org/book/) (automl介绍全面的书)

### 2019.4.18
**[17]** Dong, Jianfeng, et al. **Dual Encoding for Zero-Example Video Retrieval.** CVPR, 2019. [link](http://lixirong.net/pub/cvpr2019-dense-encoding.pdf) (孪生网络在零样本学习的应用，视频检索)

### 2019.4.28
**[18]** Frans K, Ho J, Chen X, et al. **Meta learning shared hierarchies[J].** arXiv preprint arXiv:1710.09767, 2017. [link](https://arxiv.org/pdf/1710.09767.pdf)  (openai天才高中生)

### 2019.5.1
**[19]** Wang, Duo, et al. **A Hybrid Approach with Optimization-Based and Metric-Based Meta-Learner for Few-Shot Learning.** Neurocomputing (2019).[link](https://arxiv.org/pdf/1904.03014.pdf) (MAML训练feature extractor,meta classifier做分类)

### 2019.5.6
**[20]**  Yingtian Zou , Jiashi Feng. **Hierarchical Meta Learning.** arXiv preprint arXiv:1904.09081v1, 2019. [link](https://arxiv.org/pdf/1904.09081v1.pdf)  (在MAML的基础上考虑不相似的domain)

### 2019.5.10
**[20]**  Mikhail Khodak, Maria-Florina Balcan, Ameet Talwalkar. **Provable Guarantees for Gradient-Based Meta-Learning.** arXiv preprint arXiv:1902.10644, 2019. [link](https://arxiv.org/pdf/1902.10644.pdf)  (ICML2019)


### 2019.5.11
**[21]**  **Meta-Learning: Learning to Learn Fast**[link](https://lilianweng.github.io/lil-log/2018/11/30/meta-learning.html) (一个简单介绍元学习STOA方法的博客，主要基于图像分类)

**[22]** Joaquin Vanschoren. **Meta-Learning: A Survey.** arXiv preprint arXiv:1810.03548, 2018.[link](https://arxiv.org/pdf/1810.03548.pdf)

### 2019.7.27
**[23]** NIPS2018 accepted meta-learning paper [link](http://metalearning.ml/2018/)
